---
title: "ST443 Group Project - Task 2"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

# ST443 Group Project

# Task 2: Feature selection

## Introduction

The aim of task 2 is to select properties of a molecule in a compound or random probe determine whether a compound binds to a target site on thrombin. This knowledge is required to design new compounds that can be used in drugs.

## T1.1 Data Preparation and Summary Statistics

```{r}
# Load all libraries required to execute the code in this notebook
library(ggplot2)
library(dplyr)
library(caret)
library(glmnet) # To run lasso logistic regression
library(pROC) # To plot ROC curve
library(yardstick) # To calculate balanced accuracy
```

```{r}
# Load and view the data
MLData_Task2 <- read.csv("data2.csv.gz", header=TRUE)
View(MLData_Task2)
```

#### Dataset-level statistics

```{r}
# Check for any missing valus in the dataset
any(is.na(MLData_Task2))
```

```{r}
# Calculate the Feature-Row ratio
cat("Number of features:", ncol(MLData_Task2), "\n")
cat("Number of samples:", nrow(MLData_Task2), "\n")
cat("Feature-to-sample ratio:", ncol(MLData_Task2) / nrow(MLData_Task2), "\n")
```

```{r}
# Check if the dataset is balanced, i.e. if the frequency of each class is approx. the same
table(MLData_Task2$label)
```

We can see that the data is heavily imbalanced - it contains much more observations of class -1 than of class 1.

```{r}
# Calculate the overall sparsity of the dataset (proportion of zeros in the dataset)
sum(MLData_Task2 == 0) / (nrow(MLData_Task2) * ncol(MLData_Task2))
```

As we can see, the dataset is very sparse.

#### Feature-level Statistics

```{r}
# Variance-Based Feature Selection
feature_variances <- apply(MLData_Task2, 2, var)
cat("Proportion of low-variance features (< 0.01):", mean(feature_variances < 0.01), "\n")
```

## T2.2 Training and Evaluation of Feature Selection methods

### Split data into Train and Test data

```{r}
# Random split (80% training, 20% testing)
set.seed(123)
train_indices <- sample(1:nrow(MLData_Task2), size = 0.8 * nrow(MLData_Task2))
```

```{r}
# Create training and testing datasets
train2_data <- MLData_Task2[train_indices, ]
test2_data <- MLData_Task2[-train_indices, ]

# Prepare data
train_X <- as.matrix(train2_data[, -1])  # Exclude label column
test_X <- as.matrix(test2_data[, -1])  # Exclude label column
train_Y <- factor(train2_data$label, levels = c(-1, 1), labels = c(0, 1))  # Convert to 0 and 1
test_Y <- factor(test2_data$label, levels = c(-1, 1), labels = c(0, 1))  # Convert to 0 and 1

# Verify split
cat("Training set size:", nrow(train2_data), "\n")
cat("Test set size:", nrow(test2_data), "\n")
```

### Lasso with Logistic Regression

At first, we use cross-validation on the full feature set to determine the best penalty coefficient lambda for the dataset.

```{r}
# Train Lasso Regression with cross-validation
set.seed(123)
lasso_cv_full <- cv.glmnet(train_X, train_Y, alpha = 1, family = "binomial")
```

```{r}
# Best lambda from cross-validation (the one with the lowest cross-validation error)
# For comment: The larger the lambda, the more coefficients have been sunk to zero
best_lambda <- lasso_cv_full$lambda.min
cat("Best lambda selected:", best_lambda, "\n")
```

As we realised that our dataset is heavily imbalanced, i.e. there are much more observations of class 0 than class 1, we take that into account when fitting our lasso model with the selected best lambda.

```{r}
# Calculate weights
n_class0 <- 580  # Number of samples in class 0
n_class1 <- 60   # Number of samples in class 1
n_total <- n_class0 + n_class1

weight_class0 <- n_total / n_class0
weight_class1 <- n_total / n_class1

# Assign weights to each observation
weights <- ifelse(train_Y == 0, weight_class0, weight_class1)
lasso_model <- glmnet(train_X, train_Y, alpha = 1, family = "binomial", lambda = best_lambda, weights = weights)
```

Predict the probabilities on the test data

```{r}
# Predict probabilities for the positive class
lasso_probs <- predict(lasso_model, newx= test_X, s= best_lambda, type = "response")
# Ensure that the outout is a numeric vector
lasso_probs <- as.numeric(lasso_probs)
```

Now we convert the predicted probabilities into the class labels at the optimal threshold.

```{r}
# Convert probabilities to class labels at optimal threshold
lasso_predictions <- ifelse(lasso_probs > 0.01, 0, 1) 
lasso_predictions <- as.factor(lasso_predictions)
```

Assessment of our model:

```{r}
# Compute confusion matrix
conf_matrix_lasso <- confusionMatrix(lasso_predictions, test_Y)
print(conf_matrix_lasso)

# Extract the confusion matrix table
conf_matrix_table <- conf_matrix_lasso$table
conf_matrix_table
```

```{r}
# Create dataframe with predictions and actual values to calculate balanced accuracy
data_lasso <- data.frame(
  actual_data = factor(test_Y, levels = c(0, 1)),
  prediction = factor(lasso_predictions, levels = c(0, 1))
)

# Calculate balanced accuracy
balanced_acc <- bal_accuracy(data_lasso, truth = actual_data, estimate = prediction)
print(balanced_acc)
```

#### Random Forest for Feature Selection

```{r}
library(randomForest)
library(caret)
```

For a random forest of classification trees, we usually use a random selection of m= sqrt(p) predictors as split candidates each time a split in a tree is considered. However in our case, this would mean m = sqrt(100,000) = \~316, which is way to computationally expensive. Thus we will apply a pre-selection of features by removing those features with a variance below 0.01 - given the low variance, these features will in no case serve as good predictors for our classification task.

```{r}
# Calculate the variance of each feature
feature_variances <- apply(train_X, 2, var)

# Identify features with variance >= 0.01
selected_features <- which(feature_variances >= 0.01)

# Print the number of features removed
cat("Number of features removed:", ncol(train_X) - length(selected_features), "\n")
cat("Number of features retained:", length(selected_features), "\n")
```

sqrt(30,121) still leaves \~173 features to be considered at each split. This is still too computationally expensive, thus we will try m= 2, 5 and 10 and choose the model with the best performance.

```{r}
# Define the hyperparameter grid for tuning
tune_grid <- expand.grid(
  mtry = c(2, 5, 10)  # Number of features considered as candidates each time the tree is splitt
)
```

We will use the balanced accuracy as our performance metric, because the dataset is highly imbalanced.

```{r}
# Write balanced accuracy as a function that can be accessed by trainControl
calculate_balanced_accuracy <- function(data, lev = NULL, model = NULL) {
  confusion_matrix <- table(data$obs, data$pred)
  TP <- confusion_matrix[2, 2]
  FN <- confusion_matrix[2, 1]
  TN <- confusion_matrix[1, 1]
  FP <- confusion_matrix[1, 2]

  sensitivity <- TP / (TP + FN)  # True Positive Rate
  specificity <- TN / (TN + FP)  # True Negative Rate
  balanced_acc <- (sensitivity + specificity) / 2

  return(c(BalancedAccuracy = balanced_acc))
}
```

We are using a 5-fold Cross-validation to find the optimal split nodes and values.

```{r}
# Set up cross-validation
control <- trainControl(
  method = "cv",            # Cross-validation
  number = 5,               # 5-fold CV
  verboseIter = TRUE,       # Print progress
  savePredictions = "final", # Save predictions
  summaryFunction = calculate_balanced_accuracy
)
```

We are training the model on our training dataset that only contains the selected features (variance \> 0.01). We set the number of trees to be created to 200.

```{r}
# Create new training data set with only selected features
train_X <- train_X[, selected_features]

# Train the model
set.seed(42)
rf_tuned_model <- train(
  x = train_X,
  y = train_Y,
  method = "rf",
  metric = "BalancedAccuracy",      # Metric to optimize
  tuneGrid = tune_grid,     # Hyperparameter grid
  trControl = control,
  ntree = 200,             # Number of trees
  nodesize = 10
)

# Display the best parameters
print(rf_tuned_model$bestTune)
```

```{r}
# Predicting on test set
test_X <- test_X[, selected_features]
rf_predictions <- predict(rf_tuned_model, newdata = test_X)
```

```{r}
# Confusion matrix
conf_matrix_rf <- confusionMatrix(rf_predictions, test_Y)

# Display confusion matrix
print(conf_matrix_rf)
```

```{r}
# Create dataframe with predictions and actual values to calculate balanced accuracy
data_rf <- data.frame(
  actual_data = factor(test_Y, levels = c(0, 1)),
  prediction = factor(rf_predictions, levels = c(0, 1))
)

# Calculate balanced accuracy
balanced_acc <- bal_accuracy(data_rf, truth = actual_data, estimate = prediction)
print(balanced_acc)
```

#### Recursive Feature Elimination with Gradient Boosting Machine

```{r}
library (gbm)

# Create training and testing datasets
train_data <- MLData_Task2[train_indices, ]
test_data <- MLData_Task2[-train_indices, ]

# Define the number of trees
n_trees = 100

# Define grid of lambda (shrinkage) values to evaluate
lambda_grid <- c(0.001,0.01,0.1)

# Initialize a vector to store test errors for each lambda
test_errors <- numeric(length(lambda_grid))
```

```{r}
# Loop over each lambda value
for (i in seq_along(lambda_grid)) {
  lambda <- lambda_grid[i]
  
  # Train the gbm model with the current lambda (shrinkage) value
  gbm_model <- gbm(formula = train_data$label ~ ., 
                   data = train_data[, -1],
                   distribution = "bernoulli", 
                   n.trees = num_trees, 
                   interaction.depth = 5, 
                   shrinkage = lambda, 
                   cv.folds = 5, 
                   verbose = TRUE)
  
  # Make predictions on the test set using the optimal number of trees
  predictions <- predict(gbm_model, newdata = test_X, n.trees = num_trees)
  
  # Calculate the Mean Squared Error on the test set
  test_errors[i] <- mean((predictions - test_Y)^2)
}
```
